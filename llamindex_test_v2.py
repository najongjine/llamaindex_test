import os
import sys
from dotenv import load_dotenv

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.gemini import Gemini

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY")

if not google_api_key:
    print("âŒ ì—ëŸ¬: .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

def init_rag_system():
    print("ğŸš€ [System] RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

    # ---------------------------------------------------------
    # [ìˆ˜ì •ë¨] BAAI/bge-m3 (í˜„ì¬ ê°€ì¥ ì•ˆì •ì ì´ê³  ì„±ëŠ¥ ì¢‹ì€ ëª¨ë¸)
    # ---------------------------------------------------------
    print("ğŸ“¥ [Embedding] BAAI/bge-m3 ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    # ì´ ëª¨ë¸ì€ í‘œì¤€ ì•„í‚¤í…ì²˜ë¼ trust_remote_code í•„ìš” ì—†ê³ , ì—ëŸ¬ ì•ˆ ë‚¨
    embed_model = HuggingFaceEmbedding(
        model_name="BAAI/bge-m3",
        device="cpu"  # GPU ìˆìœ¼ë©´ "cuda"
    )

    # ---------------------------------------------------------
    # LLM ì„¤ì • (Google Gemini 1.5 Flash)
    # ---------------------------------------------------------
    print("ğŸ¤– [LLM] Google Gemini 1.5 Flash ì—°ê²° ì¤‘...")
    
    llm = Gemini(
        model="models/gemini-2.5-flash", 
        api_key=google_api_key,
        temperature=0.1
    )

    # ---------------------------------------------------------
    # ì „ì—­ ì„¤ì •
    # ---------------------------------------------------------
    Settings.embed_model = embed_model
    Settings.llm = llm
    
    print("âœ… [System] ì„¤ì • ì™„ë£Œ!")

def main():
    init_rag_system()

    # ë°ì´í„° ë¡œë“œ
    if not os.path.exists("./data"):
        os.makedirs("./data")
        with open("./data/manual.txt", "w", encoding="utf-8") as f:
            f.write("LlamaIndexëŠ” ë°ì´í„° í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ê°•ì‚¬ë‹˜ì€ ì„œë²„ ê°œë°œì ì¶œì‹ ì…ë‹ˆë‹¤.")

    print("ğŸ“š [Data] ë¬¸ì„œ ì¸ë±ì‹± ì‹œì‘...")
    documents = SimpleDirectoryReader("./data").load_data()
    
    # ì¸ë±ì‹±
    index = VectorStoreIndex.from_documents(documents)
    
    # ì¿¼ë¦¬ ì—”ì§„
    query_engine = index.as_query_engine()

    # ì§ˆë¬¸í•˜ê¸°
    print("\n" + "="*30)
    user_question = "íšŒì‚¬ì—ì„œ í‚¤ìš°ëŠ” ê°œ ì´ë¦„ì´ ë­ì„?"
    print(f"â“ ì§ˆë¬¸: {user_question}")
    
    response = query_engine.query(user_question)
    
    print(f"ğŸ’¡ ë‹µë³€: {response}")
    print("="*30)

if __name__ == "__main__":
    main()