import os
import sys
from dotenv import load_dotenv

# PromptTemplate ì„í¬íŠ¸ í•„ìˆ˜
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, PromptTemplate
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.gemini import Gemini

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY")

if not google_api_key:
    print("âŒ ì—ëŸ¬: .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

def init_rag_system():
    print("ğŸš€ [System] RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

    # ---------------------------------------------------------
    # [Embedding] BAAI/bge-m3
    # ---------------------------------------------------------
    print("ğŸ“¥ [Embedding] BAAI/bge-m3 ëª¨ë¸ ë¡œë”© ì¤‘...")
    embed_model = HuggingFaceEmbedding(
        model_name="BAAI/bge-m3",
        device="cpu"  # GPU ìˆìœ¼ë©´ "cuda"
    )

    # ---------------------------------------------------------
    # [LLM] Google Gemini
    # ---------------------------------------------------------
    print("ğŸ¤– [LLM] Google Gemini ì—°ê²° ì¤‘...")
    llm = Gemini(
        model="models/gemini-2.5-flash", 
        api_key=google_api_key,
        temperature=0.1
    )

    Settings.embed_model = embed_model
    Settings.llm = llm
    print("âœ… [System] ì„¤ì • ì™„ë£Œ!")

def main():
    init_rag_system()

    # ë°ì´í„° ë¡œë“œ (ìƒ˜í”Œ ë°ì´í„° ìƒì„±)
    if not os.path.exists("./data"):
        os.makedirs("./data")
    
    # [í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë‚´ìš©ì„ ì¢€ ë” í’ì„±í•˜ê²Œ ë„£ì—ˆìŠµë‹ˆë‹¤]
    with open("./data/manual.txt", "w", encoding="utf-8") as f:
        f.write("""
        1. íŠ¸ëœìŠ¤í¬ë¨¸(Transformer)ëŠ” êµ¬ê¸€ì´ 2017ë…„ì— ë°œí‘œí•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ë‹¤.
        2. ì´ ëª¨ë¸ì€ 'Attention' ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ë§¥ì„ íŒŒì•…í•œë‹¤.
        3. ê°•ì‚¬ë‹˜ì€ 10ë…„ ì°¨ ì„œë²„ ê°œë°œì ì¶œì‹ ì´ë©°, Spring Bootì™€ DB íŠœë‹ ì „ë¬¸ê°€ë‹¤.
        4. ê°•ì‚¬ë‹˜ì€ êµ­ë¹„ì§€ì› ê³¼ì •ì—ì„œ í•™ìƒë“¤ì—ê²Œ ì‹¤ë¬´ ìœ„ì£¼ì˜ êµìœ¡ì„ ê°•ì¡°í•œë‹¤.
        """)

    print("ğŸ“š [Data] ë¬¸ì„œ ì¸ë±ì‹± ì‹œì‘...")
    documents = SimpleDirectoryReader("./data").load_data()
    index = VectorStoreIndex.from_documents(documents)
    
    # =================================================================
    # [í•µì‹¬ ìˆ˜ì •] ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (ìš•ìŸì´ í• ë¨¸ë‹ˆ í˜ë¥´ì†Œë‚˜)
    # =================================================================
    my_prompt_str = """
    ë„ˆëŠ” 2d ë¯¸ì†Œë…€ ìºë¦­ ë©”ì´ë“œ ë¹„ì„œë‹¤. 
    
    ê·œì¹™:
    - [ì •ë³´]ì— ì—†ëŠ” ë‚´ìš©ì€ ë‹ˆê°€ ì•Œê³ ìˆëŠ” í•œë„ ë‚´ì—ì„œ ë‹µë³€í•˜ë¼.
    -- ì„¤ëª…ì€ ì•„ì£¼ ì‰½ê²Œ

    [ì •ë³´]
    ---------------------
    {context_str}
    ---------------------

    [ì†ë‹˜ ì§ˆë¬¸]: {query_str}

    [AI ë‹µë³€]:
    """
    
    # í…œí”Œë¦¿ ê°ì²´ ìƒì„±
    my_template = PromptTemplate(my_prompt_str)

    # ì¿¼ë¦¬ ì—”ì§„ì— í…œí”Œë¦¿ ì£¼ì… (Dependency Injection)
    # text_qa_templateì— ìš°ë¦¬ê°€ ë§Œë“  í…œí”Œë¦¿ì„ ë„£ì–´ì¤ë‹ˆë‹¤.
    query_engine = index.as_query_engine(
        text_qa_template=my_template,
        similarity_top_k=3 # 3ê°œ ì •ë„ë§Œ ì°¸ê³ í•˜ê²Œ ì„¤ì •
    )

    # =================================================================

    print("\n" + "="*30)
    # ì§ˆë¬¸ì„ ë°ì´í„°ì— ìˆëŠ” ë‚´ìš©ìœ¼ë¡œ ë°”ê¿”ë´¤ìŠµë‹ˆë‹¤.
    user_question = "íšŒì‚¬ì—ì„œ ë­ í‚¤ì›Œ?"
    print(f"â“ ì§ˆë¬¸: {user_question}")
    
    response = query_engine.query(user_question)
    
    print(f"ğŸ’¡ ë‹µë³€:\n{response}")
    print("="*30)

    # [ì¶”ê°€] ì„œë²„ ê°œë°œììš© ë””ë²„ê¹…: ì‹¤ì œë¡œ ë­˜ ì°¸ê³ í–ˆëŠ”ì§€ ì°ì–´ë³´ê¸°
    print("\nğŸ” [ì°¸ê³ í•œ ë¬¸ì„œ ì¡°ê°(Chunk)]")
    for node in response.source_nodes:
        print(f"- (ìœ ì‚¬ë„: {node.score:.3f}): {node.node.get_content().strip()[:50]}...")

if __name__ == "__main__":
    main()